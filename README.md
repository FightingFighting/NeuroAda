# NeuroAda
This is the official repository for our EMNLP 2025 paper: NeuroAda: Activating Each Neuronâ€™s Potential for Parameter-Efficient Fine-Tuning

# Result

## Commonsense
[LLaMA-7B (0.404% trainable parameters)](https://wandb.ai/z-zhang/peft_nlg_final_reft_setting/runs/wtm20rd2?nw=nwuserzzhang)

[LLaMA-7B (0.020% trainable parameters)](https://wandb.ai/z-zhang/peft_nlg_final_reft_setting/runs/1pkira6e?nw=nwuserzzhang)
