# NeuroAda
This is the official repository for our EMNLP 2025 paper: NeuroAda: Activating Each Neuronâ€™s Potential for Parameter-Efficient Fine-Tuning

# Result
We provide the wandb link to show our results reported in our paper.
## Commonsense Reasoning
[LLaMA-7B (0.404% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/wtm20rd2?nw=nwuserzzhang)

[LLaMA-7B (0.020% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/1pkira6e?nw=nwuserzzhang)

[LLaMA-13B (0.404% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/00mn0ugz?nw=nwuserzzhang)

[LLaMA-13B (0.020% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/4yin1pcj?nw=nwuserzzhang)

[LLaMA2-7B (0.404% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/dcw5tven?nw=nwuserzzhang)

[LLaMA2-7B (0.020% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/1e9q2svg?nw=nwuserzzhang)

[LLaMA3-8B (0.404% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/w0ua4edu?nw=nwuserzzhang)

[LLaMA3-8B (0.020% trainable parameters)](https://wandb.ai/z-zhang/NeuroAda/runs/tk62q1zq?nw=nwuserzzhang)

## Arithmetic Reasoning
LLaMA-7B (0.404% trainable parameters)
LLaMA-7B (0.020% trainable parameters)

LLaMA-13B (0.404% trainable parameters)
LLaMA-13B (0.020% trainable parameters)

LLaMA2-7B (0.404% trainable parameters)
LLaMA2-7B (0.020% trainable parameters)

LLaMA3-8B (0.404% trainable parameters)
LLaMA3-8B (0.020% trainable parameters)
